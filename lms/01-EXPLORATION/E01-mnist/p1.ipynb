{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. data import    train\\n - 정규화\\n - reshape\\n2. model layer set\\n   - hyper param\\n3. 학습 train\\n   - compile\\n   - fit\\n4. 성능 및 정확도 확인    test\\n   - test data improt\\n   - evaluate\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. data import    train\n",
    " - 정규화\n",
    " - reshape\n",
    "2. model layer set\n",
    "   - hyper param\n",
    "3. 학습 train\n",
    "   - compile\n",
    "   - fit\n",
    "4. 성능 및 정확도 확인    test\n",
    "   - test data improt\n",
    "   - evaluate\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os, glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data import function\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data = 300  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    # 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size,\n",
    "                                                                                          img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "\n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx, :, :, :] = img  # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0  # 가위 : 0\n",
    "        idx = idx + 1\n",
    "\n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx, :, :, :] = img  # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1  # 바위 : 1\n",
    "        idx = idx + 1\n",
    "\n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx, :, :, :] = img  # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2  # 보 : 2\n",
    "        idx = idx + 1\n",
    "\n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx, \"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 294 입니다.\n"
     ]
    }
   ],
   "source": [
    "##1. train data import , 정규화\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "x_train, y_train = load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 48)        1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 42)        18186     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 42)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1050)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                37836     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 111       \n",
      "=================================================================\n",
      "Total params: 57,477\n",
      "Trainable params: 57,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. model hyperpram, layer set\n",
    "n_channel_1=48\n",
    "n_channel_2=42\n",
    "n_dense=36\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28, 28, 3)\n",
      "(300,)\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0921 - accuracy: 0.3400\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0576 - accuracy: 0.4567\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0291 - accuracy: 0.5933\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9427 - accuracy: 0.6533\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.7133\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.7400\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7067\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.6967\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9be8029890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 학습 train\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(x_train_norm.shape)\n",
    "print(y_train.shape)\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "#4 test 데이터 import 및 정규화\n",
    "image_dir_test_path = os.getenv(\"HOME\") + \"/aiffel/test_rcp\" #test data 폴더를 따로 생성함.\n",
    "x_test, y_test = load_data(image_dir_test_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 701.8994 - accuracy: 0.3433\n",
      "test_loss: 701.8993530273438 \n",
      "test_accuracy: 0.34333333373069763\n"
     ]
    }
   ],
   "source": [
    "#4-1 test data 를 통한 검증\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comment\n",
    "- 전체과정이 전체적으로 한 눈에 들어오지 않아서 따로 에디터를 켜놓고 한 곳에 전체 과정을 주석으로 정의 했습니다.(최상단)\n",
    "- train accuracy가 60% 초반대가 나와서 변수로 선언되어 있는 하이퍼 파라미터들을 무작위로 변경해가면서 train accuracy를70%대 까지 끌어 올렸습니다. 반면 test accuracy는 30 % 중반 대에서 잘 개선 되지 않았습니다.\n",
    "- 같은 조원분께 이미지를 받았지만 하이퍼 파라미터를 들쭉 날쭉 바꿔도 test accuracy는 개선 되지 않았습니다.\n",
    "  ** 사진을 찍은 백그라운드가 많이 달랐거나, 이미지에서 손가락이 차지하는 비중이나 위치가 유사하지 않기 때문에 어려우지 않았을가 예측됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
