{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:07:03.784048Z",
     "start_time": "2020-10-27T07:07:03.780219Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataload\n",
    "\n",
    "- https://github.com/songys/Chatbot_data/blob/master/ChatbotData%20.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:18:53.048708Z",
     "start_time": "2020-10-27T07:18:53.015256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"./Chatbot_data.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "data\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:09:44.675581Z",
     "start_time": "2020-10-27T07:09:44.661077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             12시 땡!\n",
       "1        1지망 학교 떨어졌어\n",
       "2       3박4일 놀러가고 싶다\n",
       "3    3박4일 정도 놀러가고 싶다\n",
       "4            PPL 심하네\n",
       "Name: Q, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Q'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:09:57.854447Z",
     "start_time": "2020-10-27T07:09:57.849448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     하루가 또 가네요.\n",
       "1      위로해 드립니다.\n",
       "2    여행은 언제나 좋죠.\n",
       "3    여행은 언제나 좋죠.\n",
       "4     눈살이 찌푸려지죠.\n",
       "Name: A, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['A'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:05:41.888040Z",
     "start_time": "2020-10-27T07:05:41.886387Z"
    }
   },
   "source": [
    "## data preprocessing\n",
    "\n",
    "- 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공백, 특수문자 등 전처리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:23:22.707407Z",
     "start_time": "2020-10-27T07:23:22.697515Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "\n",
    "  # 한글, 숫자, ?!. ,  제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣|0-9|?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:23:58.886637Z",
     "start_time": "2020-10-27T07:23:58.564227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            12시 땡 !\n",
       "1        1지망 학교 떨어졌어\n",
       "2       3박4일 놀러가고 싶다\n",
       "3    3박4일 정도 놀러가고 싶다\n",
       "4                심하네\n",
       "Name: Q, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = data['Q'].map(preprocess_sentence)\n",
    "answers= data['A'].map(preprocess_sentence)\n",
    "\n",
    "questions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:23:55.495958Z",
     "start_time": "2020-10-27T07:23:55.488187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     하루가 또 가네요 .\n",
       "1      위로해 드립니다 .\n",
       "2    여행은 언제나 좋죠 .\n",
       "3    여행은 언제나 좋죠 .\n",
       "4     눈살이 찌푸려지죠 .\n",
       "Name: A, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:25:27.819608Z",
     "start_time": "2020-10-27T07:25:27.815352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 병렬 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:27:49.038495Z",
     "start_time": "2020-10-27T07:27:17.550941Z"
    }
   },
   "outputs": [],
   "source": [
    "## tokenizer 선언\n",
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:27:49.054552Z",
     "start_time": "2020-10-27T07:27:49.052310Z"
    }
   },
   "outputs": [],
   "source": [
    "# 시작 엔드 토크 지정. 토크나이저 참고\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:27:52.331381Z",
     "start_time": "2020-10-27T07:27:52.327651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8355]\n",
      "END_TOKEN의 번호 : [8356]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:28:09.924490Z",
     "start_time": "2020-10-27T07:28:09.920232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8357\n"
     ]
    }
   ],
   "source": [
    "#단어장 크기 지정, 시작 끝 토큰 ++\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:36:56.391837Z",
     "start_time": "2020-10-27T07:36:56.388907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이.\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:36:56.746849Z",
     "start_time": "2020-10-27T07:36:56.745218Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:36:57.217394Z",
     "start_time": "2020-10-27T07:36:57.209518Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenier 함수\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:36:59.718634Z",
     "start_time": "2020-10-27T07:36:57.904822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8357\n",
      "필터링 후의 샘플 개수: 11823\n",
      "필터링 후의 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:37:24.443848Z",
     "start_time": "2020-10-27T07:37:24.440872Z"
    }
   },
   "outputs": [],
   "source": [
    "## 교사강요 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:37:34.830911Z",
     "start_time": "2020-10-27T07:37:34.812945Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:39:59.071405Z",
     "start_time": "2020-10-27T07:39:59.067408Z"
    }
   },
   "outputs": [],
   "source": [
    "## 전처리 패딩함수\n",
    "#0인부분 체크 1로. 아니면 0\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "# 0인부분을 연산에서 뺌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:41:53.324951Z",
     "start_time": "2020-10-27T07:41:53.319495Z"
    }
   },
   "outputs": [],
   "source": [
    "##  어텐션 시 다음 단어 제외\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:42:49.008873Z",
     "start_time": "2020-10-27T07:42:48.995368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model): # pow 거듭제곱 값을 계산 \n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:42:49.817469Z",
     "start_time": "2020-10-27T07:42:49.809913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask to zero out padding tokens\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:42:28.963916Z",
     "start_time": "2020-10-27T07:42:28.953475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷-프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # final linear layer\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이어, 모델 블럭 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:41:07.654354Z",
     "start_time": "2020-10-27T07:41:07.644374Z"
    }
   },
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "\t# 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:41:14.900868Z",
     "start_time": "2020-10-27T07:41:14.894901Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "\t# 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings) # drop out\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers): #\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:41:19.792693Z",
     "start_time": "2020-10-27T07:41:19.781085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    \n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    \n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:41:23.797385Z",
     "start_time": "2020-10-27T07:41:23.787298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "\t# 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "\t# 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "\t# 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "\t# Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:42:16.177500Z",
     "start_time": "2020-10-27T07:42:16.161701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n",
    "- 트랜스포머 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:38:57.527290Z",
     "start_time": "2020-10-27T07:38:57.510716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크하기위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:42:59.081777Z",
     "start_time": "2020-10-27T07:42:55.736094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3193600     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3720960     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8357)   2147749     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,062,309\n",
      "Trainable params: 9,062,309\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:43:25.273551Z",
     "start_time": "2020-10-27T07:43:25.267378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:43:29.073517Z",
     "start_time": "2020-10-27T07:43:29.065347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:43:35.154477Z",
     "start_time": "2020-10-27T07:43:34.892566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model comfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T07:43:46.104286Z",
     "start_time": "2020-10-27T07:43:46.086249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:20:02.682986Z",
     "start_time": "2020-10-27T08:00:21.674292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 61s 332ms/step - loss: 1.4548 - accuracy: 0.0319\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 63s 339ms/step - loss: 1.1799 - accuracy: 0.0495\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 60s 326ms/step - loss: 1.0038 - accuracy: 0.0507\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 60s 323ms/step - loss: 0.9294 - accuracy: 0.0542\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 59s 320ms/step - loss: 0.8726 - accuracy: 0.0574\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 59s 321ms/step - loss: 0.8131 - accuracy: 0.0617\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 59s 320ms/step - loss: 0.7463 - accuracy: 0.0677\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 59s 321ms/step - loss: 0.6731 - accuracy: 0.0753\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 59s 319ms/step - loss: 0.5952 - accuracy: 0.0840\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 58s 314ms/step - loss: 0.5130 - accuracy: 0.0931\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 59s 318ms/step - loss: 0.4295 - accuracy: 0.1035\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 60s 322ms/step - loss: 0.3489 - accuracy: 0.1147\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 60s 326ms/step - loss: 0.2742 - accuracy: 0.1253\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 58s 313ms/step - loss: 0.2086 - accuracy: 0.1356\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 57s 307ms/step - loss: 0.1542 - accuracy: 0.1450\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 56s 305ms/step - loss: 0.1118 - accuracy: 0.1528\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 56s 305ms/step - loss: 0.0796 - accuracy: 0.1587\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 57s 309ms/step - loss: 0.0623 - accuracy: 0.1615\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 55s 297ms/step - loss: 0.0505 - accuracy: 0.1641\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 54s 294ms/step - loss: 0.0454 - accuracy: 0.1645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b4c151110>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 평가하기\n",
    "- 입력문장 전처리, 후 대답을 예측하는 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:22:26.433667Z",
     "start_time": "2020-10-27T08:22:26.428075Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞 뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:22:26.985149Z",
     "start_time": "2020-10-27T08:22:26.978583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:22:28.009602Z",
     "start_time": "2020-10-27T08:22:27.897142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 여행가고 싶다.\n",
      "출력 : 계획을 세워보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'계획을 세워보세요 .'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('여행가고 싶다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:22:28.868292Z",
     "start_time": "2020-10-27T08:22:28.644869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 돈 내놔\n",
      "출력 : 식단조절도 하고 꾸준히 운동하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'식단조절도 하고 꾸준히 운동하세요 .'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('돈 내놔')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:22:32.611395Z",
     "start_time": "2020-10-27T08:22:32.446931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 배고파\n",
      "출력 : 얼른 맛난 음식 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'얼른 맛난 음식 드세요 .'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('배고파')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:23:16.981687Z",
     "start_time": "2020-10-27T08:23:16.736511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 인공지능 어려워\n",
      "출력 : 그런 사람은 놓치면 후회해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그런 사람은 놓치면 후회해요 .'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('인공지능 어려워')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:23:32.881051Z",
     "start_time": "2020-10-27T08:23:32.679191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 100원만 주세요\n",
      "출력 : 마음을 열까지밖에 없네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음을 열까지밖에 없네요 .'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('100원만 주세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
