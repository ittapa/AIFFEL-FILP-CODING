{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T04:23:48.763571Z",
     "start_time": "2020-11-10T04:23:48.762127Z"
    }
   },
   "source": [
    "# prj :  Spectrogram classification 모델 구현\n",
    "\n",
    "- 2차원 데이터 받아 \n",
    "- 기본버전과 skip connection 버전 모델 실습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:29.576191Z",
     "start_time": "2020-11-10T05:04:27.000223Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:29.595408Z",
     "start_time": "2020-11-10T05:04:29.580322Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = os.getenv(\"HOME\")+'/aiffel/AIFFEL_LSG/utill/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:31.785882Z",
     "start_time": "2020-11-10T05:04:29.599220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave data shape :  (50620, 8000)\n",
      "Label data shape :  (50620, 1)\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "print(\"Wave data shape : \", speech_data[\"wav_vals\"].shape)\n",
    "print(\"Label data shape : \", speech_data[\"label_vals\"].shape)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:55:31.807825Z",
     "start_time": "2020-11-10T05:55:26.868491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand num :  25714\n",
      "Wave data shape :  (8000,)\n",
      "label :  ['left']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 선택\n",
    "rand = random.randint(0, len(speech_data[\"wav_vals\"]))\n",
    "print(\"rand num : \", rand)\n",
    "\n",
    "sr = 8000 # 1초동안 재생되는 샘플의 갯수\n",
    "data = speech_data[\"wav_vals\"][rand]\n",
    "print(\"Wave data shape : \", data.shape)\n",
    "print(\"label : \", speech_data[\"label_vals\"][rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 처리와 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:55:36.192221Z",
     "start_time": "2020-11-10T05:55:36.190169Z"
    }
   },
   "source": [
    "###   2차원 Spectrogram 변형`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:45:39.323480Z",
     "start_time": "2020-11-10T05:45:39.320723Z"
    }
   },
   "outputs": [],
   "source": [
    "def wav2spec(wav, fft_size=258): # spectrogram shape을 맞추기위해서 size 변형\n",
    "    D = np.abs(librosa.stft(wav, n_fft=fft_size))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:46:04.768641Z",
     "start_time": "2020-11-10T05:46:04.761824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform shape :  (8000,)\n",
      "Spectrogram shape :  (130, 126)\n"
     ]
    }
   ],
   "source": [
    "spec = wav2spec(data)\n",
    "print(\"Waveform shape : \",data.shape)\n",
    "print(\"Spectrogram shape : \",spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T06:03:00.648857Z",
     "start_time": "2020-11-10T06:02:58.470065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50620, 8000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_data[\"wav_vals\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:53:35.490660Z",
     "start_time": "2020-11-10T05:53:28.946932Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for data in speech_data[\"wav_vals\"]:\n",
    "    data[1], data[2] = wav2spec(data[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:53:49.535946Z",
     "start_time": "2020-11-10T05:53:49.529758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label data 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:34.487749Z",
     "start_time": "2020-11-10T05:04:34.483877Z"
    }
   },
   "outputs": [],
   "source": [
    "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "label_value = target_list\n",
    "label_value.append('unknown')\n",
    "label_value.append('silence')\n",
    "\n",
    "new_label_value = dict()\n",
    "for i, l in enumerate(label_value):\n",
    "    new_label_value[l] = i\n",
    "label_value = new_label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:34.518684Z",
     "start_time": "2020-11-10T05:04:34.491511Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for v in speech_data[\"label_vals\"]:\n",
    "    temp.append(label_value[v[0]])\n",
    "label_data = np.array(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:34.527941Z",
     "start_time": "2020-11-10T05:04:34.524861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 0,\n",
       " 'no': 1,\n",
       " 'up': 2,\n",
       " 'down': 3,\n",
       " 'left': 4,\n",
       " 'right': 5,\n",
       " 'on': 6,\n",
       " 'off': 7,\n",
       " 'stop': 8,\n",
       " 'go': 9,\n",
       " 'unknown': 10,\n",
       " 'silence': 11}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:36.078439Z",
     "start_time": "2020-11-10T05:04:34.534522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0980472e-03  2.8733537e-04 -1.0553877e-03 ... -2.0539344e-03\n",
      "  -1.0159509e-03 -6.5056859e-03]\n",
      " [ 4.0703264e-05  8.0593927e-05  1.5963767e-04 ... -2.2723171e-04\n",
      "  -2.1236257e-04 -9.1046393e-05]\n",
      " [-6.5024084e-05 -9.9140612e-05 -5.0194823e-05 ... -1.7721154e-04\n",
      "  -9.7956145e-05 -6.1955427e-05]\n",
      " ...\n",
      " [ 9.6120086e-05  1.3044180e-04  8.1272890e-05 ... -7.2657538e-04\n",
      "  -3.7950958e-04 -1.4070658e-03]\n",
      " [ 2.0794477e-04  6.3185429e-04  5.6122569e-04 ...  8.2277751e-04\n",
      "   5.7218206e-04  6.1433262e-04]\n",
      " [-1.0141632e-02 -2.6850286e-03 -1.6197972e-02 ...  1.8604577e-02\n",
      "   1.8603582e-02  1.0448390e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sr = 8000\n",
    "train_wav, test_wav, train_label, test_label = train_test_split(speech_data[\"wav_vals\"], \n",
    "                                                                label_data, \n",
    "                                                                test_size=0.1,\n",
    "                                                                shuffle=True)\n",
    "print(train_wav)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:04:36.088369Z",
     "start_time": "2020-11-10T05:04:36.085822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "train_wav = train_wav.reshape([-1, sr, 1]) # add channel for CNN\n",
    "test_wav = test_wav.reshape([-1, sr, 1])\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T04:50:50.558239Z",
     "start_time": "2020-11-10T04:50:50.553838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data :  (45558, 8000)\n",
      "train labels :  (45558,)\n",
      "test data :  (5062, 8000)\n",
      "test labels :  (5062,)\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "print(\"train data : \", train_wav.shape)\n",
    "print(\"train labels : \", train_label.shape)\n",
    "print(\"test data : \", test_wav.shape)\n",
    "print(\"test labels : \", test_label.shape)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T04:51:52.868683Z",
     "start_time": "2020-11-10T04:51:52.865490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16182379e-02, 5.26165823e-03, 2.67291069e-03, ...,\n",
       "        1.45228738e-02, 7.73314834e-02, 1.02990456e-01],\n",
       "       [1.31122330e-02, 7.66591122e-03, 6.99189631e-03, ...,\n",
       "        6.44308031e-02, 5.28991707e-02, 6.11193180e-02],\n",
       "       [6.47677993e-03, 1.29101723e-02, 1.57861914e-02, ...,\n",
       "        2.88257431e-02, 6.11017924e-03, 7.61824055e-03],\n",
       "       ...,\n",
       "       [5.14591229e-04, 3.21652158e-04, 8.42790687e-05, ...,\n",
       "        1.31511217e-04, 4.84432036e-04, 1.00904074e-03],\n",
       "       [3.37703910e-04, 1.65379184e-04, 5.02230323e-05, ...,\n",
       "        1.67718190e-05, 4.97801579e-04, 9.31385206e-04],\n",
       "       [2.41642047e-04, 1.13796814e-04, 5.46092042e-06, ...,\n",
       "        5.32758804e-06, 4.79746843e-04, 9.48845642e-04]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 하이퍼 파리미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:11:11.256767Z",
     "start_time": "2020-11-10T05:11:11.244586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/aiffel/AIFFEL_LSG/utill/speech_recognition/checkpoint/wav-spec'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_epochs = 10\n",
    "\n",
    "# the save point\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/AIFFEL_LSG/utill/speech_recognition/checkpoint/wav-spec'\n",
    "\n",
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(wav, label):\n",
    "    label = tf.one_hot(label, depth=12)\n",
    "    return wav, label\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_wav, train_label))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_wav, test_label))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:07:54.161586Z",
     "start_time": "2020-11-10T05:07:54.156340Z"
    }
   },
   "source": [
    "##  model \n",
    "\n",
    "- 2차원 Spectrogram 데이터의 시간축 방향으로 Conv1D layer를 적용, 혹은 Conv2D layer를 적용 가능\n",
    "- batchnorm, dropout, dense layer 등을 이용\n",
    "- 12개의 단어 class를 구분하는 loss를 사용하고 Adam optimizer를 사용\n",
    "- 모델 가중치를 저장하는 checkpoint callback 함수 추가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:12:40.631258Z",
     "start_time": "2020-11-10T05:12:40.626278Z"
    }
   },
   "source": [
    "### 일반 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T05:14:18.557907Z",
     "start_time": "2020-11-10T05:14:17.537344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 8000, 32)          320       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 8000, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 4000, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4000, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2000, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2000, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2000, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1000, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1000, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1000, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               32768256  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 34,681,708\n",
      "Trainable params: 34,681,196\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_tensor = layers.Input(shape=(sr, 1)) ## TODO\n",
    "\n",
    "x = layers.Conv1D(32, 9, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv1D(32, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(64, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(64, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(128, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(128, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(128, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(256, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(256, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(256, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_wav = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_wav.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### loss #######\n",
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "model_wav.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "\n",
    "# check point 저장\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "\n",
    "\n",
    "#30분 내외 소요\n",
    "history_wav = model_wav.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_wav) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_wav) // batch_size,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
