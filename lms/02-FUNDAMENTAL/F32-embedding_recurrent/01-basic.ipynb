{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:07:45.158416Z",
     "start_time": "2020-09-09T08:07:45.156900Z"
    }
   },
   "source": [
    "# ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분포가설과 분산표현\n",
    "- 희소 표현(Sparse Representation) : 벡터의 특정 차원에 단어 혹은 의미를 직접 매핑하는 방식\n",
    "- 분포 가설(distribution hypothesis) :  단어 벡터, 단어간의 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:15:42.840030Z",
     "start_time": "2020-09-09T08:15:42.838519Z"
    }
   },
   "source": [
    "##  Embedding 레이어\n",
    "- 입력으로 들어온 단어를 분산 표현으로 연결해 주는 역할을 하는데 그것이 Weight에서 특정 행을 읽어오는 것과 같아 이 레이어를 룩업 테이블(Lookup Table)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:17:22.694114Z",
     "start_time": "2020-09-09T08:17:22.692346Z"
    }
   },
   "source": [
    "### 원-핫 인코딩(One-hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:18:13.160411Z",
     "start_time": "2020-09-09T08:18:11.730423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab = {      # 사용할 단어 사전 정의\n",
    "    \"i\": 0,\n",
    "    \"need\": 1,\n",
    "    \"some\": 2,\n",
    "    \"more\": 3,\n",
    "    \"coffee\": 4,\n",
    "    \"cake\": 5,\n",
    "    \"cat\": 6,\n",
    "    \"dog\": 7\n",
    "}\n",
    "\n",
    "sentence = \"i i i i need some more coffee coffee coffee\"\n",
    "# 위 sentence\n",
    "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
    "\n",
    "print(\"_input\", _input)\n",
    "\n",
    "vocab_size = len(vocab)   # 8\n",
    "\n",
    "one_hot = tf.one_hot(_input, vocab_size)\n",
    "print(one_hot.numpy())    # 원-핫 인코딩 벡터를 출력해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:18:19.346512Z",
     "start_time": "2020-09-09T08:18:19.193071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Weight\n",
      "[[-0.59758     0.66687477]\n",
      " [ 0.15532106  0.59673274]\n",
      " [ 0.6042737   0.4549005 ]\n",
      " [-0.7078802  -0.12985265]\n",
      " [-0.55014    -0.3667564 ]\n",
      " [ 0.2249763   0.13968456]\n",
      " [ 0.5467336  -0.20054692]\n",
      " [ 0.5241878   0.09636933]]\n",
      "\n",
      "One-Hot Linear Result\n",
      "[[-0.59758     0.66687477]\n",
      " [-0.59758     0.66687477]\n",
      " [-0.59758     0.66687477]\n",
      " [-0.59758     0.66687477]\n",
      " [ 0.15532106  0.59673274]\n",
      " [ 0.6042737   0.4549005 ]\n",
      " [-0.7078802  -0.12985265]\n",
      " [-0.55014    -0.3667564 ]\n",
      " [-0.55014    -0.3667564 ]\n",
      " [-0.55014    -0.3667564 ]]\n"
     ]
    }
   ],
   "source": [
    "distribution_size = 2   # 보기 좋게 2차원으로 분산 표현하도록 하죠!\n",
    "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
    "one_hot_linear = linear(one_hot)\n",
    "\n",
    "print(\"Linear Weight\")\n",
    "print(linear.weights[0].numpy())\n",
    "\n",
    "print(\"\\nOne-Hot Linear Result\")\n",
    "print(one_hot_linear.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:20:58.502483Z",
     "start_time": "2020-09-09T08:20:58.486883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding을 진행할 문장: (1, 3)\n",
      "Embedding된 문장: (1, 3, 100)\n",
      "Embedding Layer의 Weight 형태: (64, 100)\n"
     ]
    }
   ],
   "source": [
    "some_words = tf.constant([[3, 57, 35]])\n",
    "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
    "\n",
    "print(\"Embedding을 진행할 문장:\", some_words.shape)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
    "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
    "# 각 단어는 100차원으로 분산표현 할 것입니다.\n",
    "\n",
    "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:27:37.031080Z",
     "start_time": "2020-09-09T08:27:37.029578Z"
    }
   },
   "source": [
    "## Recurrent layer_RNN\n",
    "- 문장이나 영상, 음성 등의 데이터는 한 장의 이미지 데이터와는 사뭇 다른 특성을 가집니다. 바로 순차적인(Sequential) 특성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:41:17.731128Z",
     "start_time": "2020-09-09T08:41:17.702123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN에 입력할 문장: What time is it ?\n",
      "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
      "입력 문장 데이터 형태: (1, 5)\n",
      "\n",
      "Embedding 결과: (1, 5, 100)\n",
      "Embedding Layer의 Weight 형태: (5, 100)\n",
      "\n",
      "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n",
      "\n",
      "RNN 결과 (최종 Step Output): (1, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "print(\"RNN에 입력할 문장:\", sentence)\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "print(\"Embedding을 위해 단어 매핑:\", sentence_tensor.numpy())\n",
    "print(\"입력 문장 데이터 형태:\", sentence_tensor.shape)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
    "\n",
    "rnn_seq_layer = \\\n",
    "tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
    "rnn_seq_out = rnn_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
    "\n",
    "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
    "rnn_fin_out = rnn_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T08:53:40.834927Z",
     "start_time": "2020-09-09T08:53:40.833446Z"
    }
   },
   "source": [
    "## lstm \n",
    "- 기울기 소실 문제를 해결하기 위해 고안된 RNN 레이어\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:03:21.234884Z",
     "start_time": "2020-09-09T09:03:21.199443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "LSTM 결과 (최종 Step Output): (1, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n"
     ]
    }
   ],
   "source": [
    "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
    "lstm_seq_out = lstm_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
    "\n",
    "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
    "lstm_fin_out = lstm_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:26:30.784997Z",
     "start_time": "2020-09-09T09:26:30.783097Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## 양방향 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:26:31.621211Z",
     "start_time": "2020-09-09T09:26:31.591073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 데이터 형태: (1, 5, 100)\n",
      "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
    "\n",
    "bi_rnn = \\\n",
    "tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
    ")\n",
    "bi_out = bi_rnn(emb_out)\n",
    "\n",
    "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 양방향(Bidirectional) RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T05:58:07.892139Z",
     "start_time": "2020-09-10T05:58:06.290090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 데이터 형태: (1, 5, 100)\n",
      "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
    "\n",
    "bi_rnn = \\\n",
    "tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
    ")\n",
    "bi_out = bi_rnn(emb_out)\n",
    "\n",
    "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
