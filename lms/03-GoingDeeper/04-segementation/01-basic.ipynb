{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentaton\n",
    "\n",
    "- 인스턴스 세그멘테이션(instance segmentation)\n",
    "- 시맨틱 세그멘테이션(semantic segmentation)\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/semantic_vs_instance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semantic segmentation\n",
    "\n",
    "- u-net\n",
    "    + 572x572 = 388x388\n",
    "    + 2개 클래스 세크멘테이션 맵 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instance segmentation\n",
    "- 물체 검출(object detection) 모델로 각 개체를 구분하고 이후에 각 개체 별로 세그멘테이션을 수행하면 인스턴스 세그멘테이션을 할 수\n",
    "\n",
    "- Mask R-CNN \n",
    "    + fater-r-cnn의 roi<(region-r-cnn)을 계승.\n",
    "    + RolAlign, 클래스별 마스크 분리\n",
    "    + 클래스별 Object Detection과 Semantic Segmentation 을 사실상 하나의 Task로 엮어냄\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GC-5-L-FasterRCNN-01.png)\n",
    "    +  RoIPool Layer는 다양한 RoI 영역을 Pooling을 통해 동일한 크기의 Feature map으로 추출해 내는 레이어입니다. 이후 이 고정 사이즈의 Feature map을 바탕으로 바운딩 박스와 object의 클래스를 추론\n",
    "    \n",
    "    \n",
    "    + Quantization 모든 그림의 크기가\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T02:42:44.594478Z",
     "start_time": "2020-10-29T02:42:44.592181Z"
    }
   },
   "source": [
    "## FCN\n",
    "\n",
    "- UPSAMPLING\n",
    "    + Deconvolution\n",
    "    + interplation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## u -net\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/u-net.max-800x600.png)\n",
    " - 논문에서는 네트워크 구조를 좌측의 Contracting path와 우측의 Expansive path 두 가지로 구분\n",
    "\n",
    "```\n",
    "분합니다.\n",
    "우측의 Contracting path는 일반적으로 우리가 사용해왔던 Convolution network와 유사한 구조를 가집니다. 각 블록은 두개의 3x3 convolution 계층과 ReLu를 가지고 그 뒤로 downsampling을 위해서 2x2의 커널을 2 stride로 max pooling을 하게 됩니다. Downsampling을 거친 후 다음 convolution의 채널 크기는 두 배씩 늘어나도록 설계되었습니다.\n",
    "Expansive path에서는 각 블록에 2x2 up-convolution이 붙어 채널이 절반씩 줄어들고 특성 맵의 크기는 늘어납니다. Expansive path의 블록은 contracting block과 동일하게 3x3 convolution이 두 개씩 사용되었습니다.\n",
    "두 Path에서 크기가 같은 블록의 출력과 입력은 skip connection처럼 연결해주어 low-level의 feature를 활용할 수 있도록 하였습니다. 마지막에는 1x1 convolution으로 원하는 시맨틱 세그멘테이션 맵을 얻을 수 있습니다.\n",
    "\n",
    "결과적으로는, 입력으로 572x572 크기인 이미지가 들어가고 출력으로 388x388의 크기에 두 가지의 클래스를 가진 세그멘테이션 맵(segmentation map)이 나옵니다.\n",
    "\n",
    "마지막 세그멘테이션 맵의 크기가 입력 이미지와 다른 것은 앞에서 이야기한 것처럼 세그멘테이션 맵을 원하는 크기로 조정하여(resize) 해결할 수 있습니다. 원본 이미지에 맞게 크기를 조정해주면 위에서 봤던 우리가 원하는 시맨틱 세그멘테이션 결과를 얻을 수 있게 되죠.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deeplab\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/deeplab_v3.max-800x600.png)\n",
    "\n",
    "\n",
    "```\n",
    "인코더는 이미지에서 필요한 정보를 특성으로 추출해내는 모듈이고 디코더는 추출된 특성을 이용해 원하는 정보를 예측하는 모듈입니다. 3x3 convolution을 사용했던 U-Net과 달리 DeepLabV3+는 Atrous Convolution을 사용하고 있습니다. 그리고 이로 Atrous Convolution을 여러 크기에 다양하게 적용한 것이 ASPP(Atrous Spatial Pyramid Pooling)입니다. DeepLab V3+는 ASPP가 있는 블록을 통해 특성을 추출하고 디코더에서 Upsampling을 통해 세그멘테이션 마스크를 얻고 있습니다.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T03:01:37.943691Z",
     "start_time": "2020-10-29T03:01:37.937562Z"
    }
   },
   "source": [
    "- Atrous Convolution\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/atrous_conv.gif)\n",
    "\n",
    "- Spatial Pyramid Pooling()\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GC-5-L-SPP.max-800x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가\n",
    " - error metrics\n",
    " \n",
    " ![](https://aiffelstaticprd.blob.core.windows.net/media/images/error_metric.max-800x600.jpg)\n",
    " \n",
    " - 마스크 IoU (Mask Intersection-over-Union)\n",
    " \n",
    "```\n",
    "# sample for mask iou\n",
    "intersection = np.logical_and(target, prediction)\n",
    "union = np.logical_or(target, prediction)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upsampling\n",
    "\n",
    "1. nearest neighbor : 가까운 값 그대로 적용\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/upsampling1.png)\n",
    "\n",
    "2. Bilinear Interpolation: 두축() 통해..\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/bi_interpolation.png)\n",
    "\n",
    "3. Transposed Convolution\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/transposed_conv.max-800x600.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
