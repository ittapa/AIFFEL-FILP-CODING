{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class activation map\n",
    "\n",
    "- xai(explainable artificial intelligence)   \n",
    "<br/>\n",
    "1. Explainable AI   \n",
    "2. CAM: Class Activation Map   \n",
    "3. Grad-CAM   \n",
    "4. ACoL: Adversarial Complementary Learning   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAP\n",
    "- global average Pooling\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GC-3-L-4.max-800x600.png)\n",
    "\n",
    "- 특성 맵을 채널 별로 평균을 낸 값\n",
    "-  최적화할 파라미터가 존재하지 않으므로 과적합(overfitting)을 방지할 수 있다고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cam\n",
    "- class activation map\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GC-3-L-5.max-800x600.png)\n",
    "\n",
    "\n",
    "- gap 을 통해 추출\n",
    "- 단점, gap layer 반드시 추가, <해야하므오로 성능감소, fine-tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad-cam\n",
    "\n",
    "- 그래디언트를 통한 Weight Score 계산\n",
    "\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GC-3-L-9.max-800x600.png)\n",
    "\n",
    "- 모델 구조 변경없이 적용가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 약지도 학습\n",
    "- weakly supervised learning\n",
    "- cam, grad-cam, ACol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T04:47:56.727751Z",
     "start_time": "2020-11-12T04:47:56.723730Z"
    }
   },
   "source": [
    "- 약지도 학습 vs 준지도학습(semi_supervised learning)\n",
    "\n",
    "- 약지도 학습 포괄\n",
    "    + incomplete supervision : 학습 데이터 중 일부에만 라벨이 달려 있는 경우 (예: 개와 고양이 분류 학습시 10000개의 이미지 중 1000개만 라벨이 있는 경우) 이 경우가 일반적으로 말하는 준지도학습과 같은 경우입니다.\n",
    "\n",
    "    + inexact supervision : 학습데이터의 라벨이 충분히 정확하게 달려있지 않은 경우. (예: 개나 고양이를 Object Detection 또는 Semantic Segmentation해야 하는데, 이미지 내에 정확한 bounding box는 주어져 있지 않고 이미지가 개인지 고양인지 정보만 라벨로 달려있는 경우)\n",
    "\n",
    "    + inaccurate supervision : 학습 데이터에 Noise가 있는 경우 (예: 개나 고양이의 라벨이 잘못 달려있는 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACol: Adversarial Complementary\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GC-3-L-13.max-800x600.png)\n",
    "\n",
    "-  CAM 모델이 특정 부위에 집중해 학습하는 것을 막기 위해서 ACoL은 브랜치를 두 가지로 두어 너무 높은 점수를 지워줌으로서 주변의 특성 또한 반영하도록 했습니다. 이러한 과정을 논문에서는 Adversial, 즉 적대적인 학습방법\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T07:11:44.036393Z",
     "start_time": "2020-11-12T07:11:44.032410Z"
    }
   },
   "source": [
    "- cam, grad-cam a문제점\n",
    "    + 특징이 주로 나타나는 위치에 중점적으로 활성화\n",
    "    + 물체는 부분이 아닌 전체적인 형태와 윤곽 구분이 중요\n",
    "    \n",
    "    \n",
    "-  ACoL은 브랜치를 두 가지로 두어 너무 높은 점수를 지워줌 => 즉 적대적인 학습방법\n",
    "\n",
    "- (주황) 특성 맵은 GAP을 거쳐 CAM에서 보았던 소프트맥스 레이어인 Classifier A를 거치게 됩니다. 이 브랜치는 loss로 학습, Classifier A는 쉽게 전체적인 이미지를 보고 클래스를 판별할 수 있음\n",
    "\n",
    "- (녹) Classifier B는 A의 CAM에서 크게 활성화된 영역을 지운 활성화 맵에서 분류를 해야하기 때문에 더 어려운 문제를 푸는 것으로 볼 수 있음\n",
    "\n",
    "- Classifier A와 Classifier B를 학습시킴으로써 더 넓은 영역을 판별의 근거로 삼을 수 있음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T07:19:44.693149Z",
     "start_time": "2020-11-12T07:19:44.561110Z"
    }
   },
   "source": [
    "### 1x1 conv\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GC-3-L-15.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T07:19:55.456074Z",
     "start_time": "2020-11-12T07:19:55.451838Z"
    }
   },
   "source": [
    "- CAM에서는 CAM을 얻기 위해서 대상이 되는 네트워크에 feed forward를 하고 활성화 맵과 가중치 계산을 다시 해주어야 합니다. 이 과정은 관찰하고자 하는 분류 모델의 feed forward와 별개의 작업이므로, 물체 검출을 위한 모델로 사용하기 위해서는 모델의 feed forward 외 별도의 연산을 해주어야 하는 단점이 있습니다.\n",
    "\n",
    "- ACoL 논문은 이를 개선하기 위해서 커널 사이즈는 1x1, 출력 채널의 개수는 분류하고자 하는 클래스 개수를 가진 컨볼루션 레이어를 특성 맵에 사용하고 여기에 GAP를 적용하여 Network in Network에서 본 구조와 유사한 방식을 사용하고 있습니다. 여기서 컨볼루션 레이어의 출력값은 곧바로 활성화 맵이 됩니다. 이렇게 구해진 활성화 맵과 CAM을 비교한 결과를 위 그림의 왼쪽에서 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
