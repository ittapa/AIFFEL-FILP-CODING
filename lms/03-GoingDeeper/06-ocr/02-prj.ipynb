{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  OCR\n",
    "\n",
    "- Overall sturcture of OCR\n",
    "- SynthText\n",
    "- Recognition model\n",
    "- End-to-End OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:10:59.294447Z",
     "start_time": "2020-11-23T07:10:59.288600Z"
    }
   },
   "source": [
    "# libarary install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:10:59.276946Z",
     "start_time": "2020-11-23T07:10:53.713564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Collecting lmdb\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/b6/18/48109367e0d1bc9f7eed0d387cd5b50dd0e19c299bbbfe8b21246455fa48/lmdb-1.0.0.tar.gz (876 kB)\n",
      "\u001b[K     |████████████████████████████████| 876 kB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lmdb\n",
      "  Building wheel for lmdb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lmdb: filename=lmdb-1.0.0-cp38-cp38-linux_x86_64.whl size=269146 sha256=de173b3cf588f2847cb5d60225f6536e1e074ac509f06cccf03e5fa0d43cf43f\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/68/4b/5c/4602efd08e13dbc70609a3e309cad8ea8b5383a08b1b84a5ed\n",
      "Successfully built lmdb\n",
      "Installing collected packages: lmdb\n",
      "Successfully installed lmdb-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:07:59.276834Z",
     "start_time": "2020-11-30T06:07:57.374200Z"
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "import six\n",
    "import math\n",
    "import lmdb\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data set \n",
    "\n",
    "- MJ Synth\n",
    "- SynthTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:08:02.653466Z",
     "start_time": "2020-11-30T06:08:02.650273Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.path.join(os.getenv('HOME'),'lsg/data/mj')\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:08:03.762813Z",
     "start_time": "2020-11-30T06:08:03.642921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lsg/data/mj\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition model\n",
    "\n",
    "- An End-to-End Trainable Neural Network for Image-based SequenceRecognition and Its Application to Scene Text Recognition\n",
    "\n",
    "- https://arxiv.org/pdf/1507.05717.pdf\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/e-23-2.crnn.png)\n",
    "\n",
    "\n",
    "- 구조\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/e-23-3.crnn_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:08:05.036092Z",
     "start_time": "2020-11-30T06:08:05.030783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of characters is 36\n"
     ]
    }
   ],
   "source": [
    "NUMBERS = \"0123456789\"\n",
    "ENG_CHAR_UPPER = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "TARGET_CHARACTERS = ENG_CHAR_UPPER + NUMBERS\n",
    "print(f\"The total number of characters is {len(TARGET_CHARACTERS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## path set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T07:00:37.565407Z",
     "start_time": "2020-11-30T07:00:37.557230Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "HOME_DIR = os.getenv('HOME')+'/lsg/data/mj'\n",
    "\n",
    "TRAIN_DATA_PATH = HOME_DIR+'/MJ_train'\n",
    "VALID_DATA_PATH = HOME_DIR+'/MJ_valid'\n",
    "TEST_DATA_PATH = HOME_DIR+'/MJ_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T07:00:38.119891Z",
     "start_time": "2020-11-30T07:00:38.115829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/lsg/data/mj/MJ_train'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:17:07.209730Z",
     "start_time": "2020-11-30T08:17:07.146889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "original image width:72, height:31\n",
      "target_img_size:(74, 32)\n",
      "display img shape:(74, 32, 3)\n",
      "label:label-000000001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=74x32 at 0x7FCA1D2E1DF0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "original image width:82, height:31\n",
      "target_img_size:(84, 32)\n",
      "display img shape:(84, 32, 3)\n",
      "label:label-000000002\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAAgCAIAAAADushBAAAKJklEQVR4nHVZW3PaPBCVLPmOMRDa9DLt9P/0/z92OtNpwoQECAZfJVnfwwnbxeTzQ8bYsrR79uzZlSJ//vwppQyCYBxHKaVzDvdBEODGe++9D4JASimE8N4LIeiGPlRKOefwUEqJwXiFJzTeOaeU8t6P44gbzI8n3nul1GR+moHPgw/xCuO5hfirtXbOkYNkOX7qIAi4S0KI1WqVJIkQ4vn5GSjwVblZNJEQAmvwAdwgMhcTwg5/c9Fg+tw5Rz/JBtxwm3ER1oQInmAepdQ4jlgaMdaT779//w5ngiD48uVLVVWn08laSwuTt7eo8790gzEwYsIdgpUG0JwwkXhx6xt3j+65MRPq4Z6bJIQIyCXv/WKxANuHYQD9rLXAniJAH99mAX+Fn5Q7E2ZygnDa07QcAkJEKcWTiDvDbUNsKE4T5pJ53ntN4AkhZrMZFtjtdtbaLMuGYaDlKXpk9LsqwJHGwsSUCasxFU97woI7iXtKXQgT16lJhCc0JPPoIZFF8wzs+x7OLxaLl5eXuq4x+v7+HipwPp+Px6MxBkbQLLfw4y38n4SaB5bElWPHYSW4seIkz3moyU8OCg8GD+Eb3DwDd7sd/Mmy7Nu3b1EUee/jOI7jOAxDpVRRFF+/fs3zHMKepulyucyyTFwyCmyke24uYJ0gdRsffDuxkl6J64ugcc7RW3xI81C0J5x9Ezx66px7fHz89OlTkiTOuc+fP//9+zdJEq21934YBq211nq1Wiml4jiezWZYzFp7Op2qqiIcsTZFldyYWPCuQCJZuGEUUnGtZ3xaIgv5RtKAt7zQ4KfmHBvH0Rjz9PSUZdlisYiiaD6fv2mD1sfjUWu9WCySJFFKKaUAyjiOYRhaa6uqyrLs7u6OrLHW7nY7iOU4jrjhppNZPJgT9vprtec0/j8d4Uwh3aFgECKaa+CnT5/2+33XdV3XlWUJ/sNPhNcYUxSF1jqKIiFEXdeHwyHP89VqVRSFMQYDrLWIkrVWCPH09CSEmM/ns9nMOYf527alRoUHf6KaaIoEkxKyFpPzi+aZaM0kfWgGTWFP0zRN0/v7e5Q3tFnOuSiKUPycc3Ec4zmuKIqWy2UYhhDtJEmMMd57ay0mwZwfP35USkE1pJR5nrdta609HA6oJpgB3QTns7iuIHgYhuF8Po/jGLlW1zX5ybNmwhdxLbcYowGtlNIY07btYrGgiAkhqqpSlwtJDqrDyiiKkiQBnzl7nXO73U4plaaplLIoCh4W+O+c2263d3d3URQBlHEc9/s94POX3u5NlplwzGaz+XyOAm6tbZqGL02oyetiNIHgLZcpbay1r6+v5/MZMRzHse/7tm1XqxWmWC6XQAFSD7wAPAQf0gCwu65DypBZxpj9fi8vtV1KWZZlWZZBEMRxDFfDMNxsNvC/KIrZbOa97/veWou/zjljzDiOURQhywQrGcCISwOUj3J+ohFX7W3f93VdK6XatkWS87dpmnrvm6apqipJEsSTeHE+n6EU5C3VNhh0PB6rqqK1lVI/fvyQUjrnHh4eIKVxHGdZdjwe0zTFFgMUcM4hlcgYY8zhcJhwfiL7XEd4n0fs0PQaT2Ex0EXcAN7r62vXdVLKvu8hV+M4zufzsiyJBcYY9EI0FdnqvW/blmcmKujbBkNrcSk3kNL5fB5FEWxAfpHRlA7GGGst0pAuWlGyakfy7q97JE31IE1Tay1mh1yjVg/DEMfx+Xw+nU4YCf2DXEVRBIABDcoejIa2461SarlcbrdbCATeEj/X6zW6RjI6SRKYfjwe+77HE6gd0JFSAjLQKkkSTEi4NE3De0d/2SnzZuGfehEeYRiWZdl1HRLs9fW1bdthGPAx5RLkmsiChN/v90EQAAitNeCo67osS7QM0AvqAsHGtm3hWxAEaLHhOZbAbHEcw7bVaoV7HsYkSdbrNXV1CFhVVcYYrTX0Fbs1EOdN7Slb6romDSeQoKgIIEJKJxaEIokq8pA4//LyEkWRtfZ8PkPe7u7u8KG19s+fP8vlkujati12OHVd53kOiOE2VoHp4qJnbduCEVgdTPTeR1GUpilqsJRyv9+vVqvZbGaMQbV2zjVNY60dx/FfzhMfkNUkS0EQ4C/tpSB+aAepb+OZRgonLvtKnItwTem67ng8LpfLcRzTNIV0VVVlrS2KApEB+8SlXDnniqJA2M/nc9u2XMCMMaCq1joMQ9Sguq4BMTYmmO10Om02mzfBE2xLJK47Cn/pWMgNEDIMQ6AIaMT1hsRf+lMyzlq72Wzwoda673sp5Xa7DYIgiiIwU1xODZAvQRCgF6J6gc/5dh2JkGVZnudZlllru66DCmIGShDn3Pl8RurleY6CrYnAJOyebTwIC8pP2Hc4HPAVYIZ7kElUPqDGm3bUDqgpNR4PDw+z2SzPc8Da9z2qKXoEf7PnoeM9LARP1uu1uHQZRVEAfWoxITFN0zw9PcF5MLeuay1YSRRst0Bc4EQgXaTByCU+LEkSNC3ovegIkWcHxU0p1TRNXddkvZTy5eWlKAoAypUYMgnU0FZZa9FEoivpuk5rjXJrrUXDioCdTieART567/W7h2cTKycU8OwwV1yrLt/bgnV5nqMPo4YMcPAdOEEPZfHeo44Ids6HeDZNo5SCquV53vc9EdY5V9d1GIZpmgIplE983rZtGIZkLfRCE6+ITgSzvN5jSNYO3WoEYcT3atjAiYsQoo7ked40DcQyDENjjFIKYj6yk3JqNGgVpdTxeGzbtixLVPuqqpxzHz58QOaj1BOmmIEunD4gI6CLmnhOxIaMUUAmbJfv7bcEO4Hwl1Nx+oR6DwBxOp0wTxiG6/W6qqo0TV9fX4dhAByCqSaPBC5jzHa7pckBGW0uSbaGYUiSBO4cj8cwDCH7UkpUFo9dHYkzKEeei8uxIfnMgeAHbxNqTHKHKwinhnPu9+/fSimQPIoi5xx2B8MwgBq0n/esRaWCivthGDabDS9GuFkul6h/p9MJZxDg136/h3D+29Uh4GQljx5ntWcbg0nw6adkXfStTPLjFL75McZA7eBAFEVhGKI/8d6jyyS5mVBjkq14+/j4iHqEkV3XUVcC1zQ3Yrw+4p+YTqCIi/DCDu4bx24iDRyLib7SExQwTI4cQSFAjuR5jle0kxXXIj2JED9NMsb8+vULwkHDNMo9rysTbhPTKME452/d47lAKYMl+EjJDpsooQgLaihpwmEYUFNxodXDzHVdgx20dadSMpmfogVLNCU5lUEKWsCOwcbrk3By7N1DIp4XfIy8HDnwgHM9p3tKDXFTbjAVCios1FqnaUpHbDiVkJd/HExkm2Oqeay4G4TFyA4DyYfJJ5z8/BNSKf7VbTm4RW3Co1t8ORZoLpumwXO0mGmalmUJYUd14Au9RV5c85xDJVhXy+MzGTMZ4Nl/V0jh5KUC3aomfiL7/q+CcG95arxLHCjCMAzYWQVBAOFM0/T5+RlnFjDjPz7uIp2ZyfHSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=84x32 at 0x7FCA1D2C5940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "original image width:115, height:31\n",
      "target_img_size:(100, 32)\n",
      "display img shape:(100, 32, 3)\n",
      "label:label-000000003\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x32 at 0x7FCA1D2E18E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "original image width:140, height:31\n",
      "target_img_size:(100, 32)\n",
      "display img shape:(100, 32, 3)\n",
      "label:label-000000004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x32 at 0x7FCA1D2E1E80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "env = lmdb.open(TRAIN_DATA_PATH, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "with env.begin(write=False) as txn:\n",
    "    for index in range(1, 5):\n",
    "        label_key = 'label-%09d'.encode() % index\n",
    "        print(txn.get(label_key))\n",
    "        label = label_key.decode('utf-8')\n",
    "      \n",
    "        img_key = 'image-%09d'.encode() % index\n",
    "        imgbuf = txn.get(img_key)\n",
    "        buf = six.BytesIO()\n",
    "        buf.write(imgbuf)\n",
    "        buf.seek(0)\n",
    "        try:\n",
    "            img = Image.open(buf).convert('RGB')\n",
    "\n",
    "        except IOError:\n",
    "            img = Image.new('RGB', (100, 32))\n",
    "            label = '-'\n",
    "        width, height = img.size\n",
    "        print('original image width:{}, height:{}'.format(width, height))\n",
    "        \n",
    "        target_width = min(int(width*32/height), 100)\n",
    "        target_img_size = (target_width,32 )\n",
    "        \n",
    "        print('target_img_size:{}'.format(target_img_size))\n",
    "        \n",
    "        img = np.array(img.resize(target_img_size)).transpose(1,0,2)\n",
    "       \n",
    "        print('display img shape:{}'.format(img.shape))\n",
    "        print('label:{}'.format(label))\n",
    "        display(Image.fromarray(img.transpose(1,0,2).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:17:12.052806Z",
     "start_time": "2020-11-30T08:17:12.033864Z"
    }
   },
   "outputs": [],
   "source": [
    "class MJDatasetSequence(Sequence):\n",
    "    def __init__(self, \n",
    "                      dataset_path,\n",
    "                      label_converter,\n",
    "                      batch_size=1,\n",
    "                      img_size=(100,32),\n",
    "                      max_text_len=22,\n",
    "                      is_train=False,\n",
    "                      character=''\n",
    "                ):\n",
    "        \n",
    "        self.label_converter = label_converter\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.character = character\n",
    "        self.is_train = is_train\n",
    "        self.divide_length = 100\n",
    "\n",
    "        self.env = lmdb.open(dataset_path, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            num_samples = int(txn.get('num-samples'.encode()))\n",
    "            self.num_samples = int(num_samples)\n",
    "            self.index_list = [index + 1 for index in range(self.num_samples)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return math.ceil(self.num_samples/self.batch_size/self.divide_length)\n",
    "        return math.ceil(self.num_samples/self.batch_size/self.divide_length)\n",
    "    \n",
    "    def _get_img_label(self, index):\n",
    "        # Return image array and label in string\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            label_key = 'label-%09d'.encode() % index\n",
    "            label = txn.get(label_key).decode('utf-8')\n",
    "            img_key = 'image-%09d'.encode() % index\n",
    "            imgbuf = txn.get(img_key)\n",
    "\n",
    "            buf = six.BytesIO()\n",
    "            buf.write(imgbuf)\n",
    "            buf.seek(0)\n",
    "            try:\n",
    "                img = Image.open(buf).convert('RGB')\n",
    "\n",
    "            except IOError:\n",
    "                img = Image.new('RGB', self.img_size)\n",
    "                label = '-'\n",
    "            width, height = img.size\n",
    "            \n",
    "            target_width = min(int(width*self.img_size[1]/height), self.img_size[0])\n",
    "            target_img_size = (target_width,self.img_size[1] )\n",
    "            img = np.array(img.resize(target_img_size)).transpose(1,0,2)\n",
    "            label = label.upper()[:self.max_text_len]\n",
    "            out_of_char = f'[^{self.character}]'\n",
    "            label = re.sub(out_of_char, '', label)\n",
    "\n",
    "        return (img, label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indicies = self.index_list[\n",
    "            idx*self.batch_size:\n",
    "            (idx+1)*self.batch_size\n",
    "        ]\n",
    "        input_images = np.zeros([self.batch_size, *self.img_size, 3])\n",
    "        labels = np.zeros([self.batch_size, self.max_text_len], dtype='int64')\n",
    "\n",
    "        input_length = np.ones([self.batch_size], dtype='int64')*self.max_text_len\n",
    "        label_length = np.ones([self.batch_size], dtype='int64')\n",
    "\n",
    "        for i, index in enumerate(batch_indicies):\n",
    "            img, label = self._get_img_label(index)\n",
    "            encoded_label = self.label_converter.encode(label)\n",
    "            width = img.shape[0]\n",
    "            input_images[i,:width,:,:] = img\n",
    "            if len(encoded_label) > self.max_text_len:\n",
    "                continue\n",
    "            labels[i,0:len(encoded_label)] = encoded_label\n",
    "            label_length[i] = len(encoded_label)\n",
    "\n",
    "        inputs = {\n",
    "            'input_image': input_images,\n",
    "            'label': labels,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "        }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size, 1])}\n",
    "        return inputs, outputs\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.index_list =  [index + 1 for index in range(self.num_samples)]\n",
    "        if self.is_train :\n",
    "            np.random.shuffle(self.index_list)\n",
    "            return self.index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:17:15.670608Z",
     "start_time": "2020-11-30T08:17:15.665994Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabelConverter(object):\n",
    "     \"\"\" Convert between text-label and text-index \"\"\"\n",
    "\n",
    "     def __init__(self, character):\n",
    "         self.character = \"-\" + character\n",
    "         self.label_map = dict()\n",
    "         for i, char in enumerate(self.character):\n",
    "             self.label_map[char] = i\n",
    "\n",
    "     def encode(self, text):\n",
    "         encoded_label = []\n",
    "         # [[YOUR CODE]]\n",
    "\n",
    "         return np.array(encoded_label)\n",
    "\n",
    "     def decode(self, encoded_label):\n",
    "         target_characters = list(self.character)\n",
    "         decoded_label = \"\"\n",
    "         for encode in encoded_label:\n",
    "             decoded_label += self.character[encode]\n",
    "         return decoded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:17:17.947598Z",
     "start_time": "2020-11-30T08:17:17.943962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encdoded_text:  []\n",
      "Decoded_text:  \n"
     ]
    }
   ],
   "source": [
    "label_converter = LabelConverter(TARGET_CHARACTERS)\n",
    "\n",
    "encdoded_text = label_converter.encode('HELLO')\n",
    "print(\"Encdoded_text: \", encdoded_text)\n",
    "decoded_text = label_converter.decode(encdoded_text)\n",
    "print(\"Decoded_text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:17:19.993995Z",
     "start_time": "2020-11-30T08:17:19.991059Z"
    }
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args): # CTC loss를 계산하기 위한 Lambda 함수\n",
    "    labels, y_pred, label_length, input_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:27:53.002206Z",
     "start_time": "2020-11-30T08:27:52.995789Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_crnn_model(input_shape=(100,32,3), characters=TARGET_CHARACTERS):\n",
    "    num_chars = len(characters)+2\n",
    "    image_input = layers.Input(shape=input_shape, dtype='float32', name='input_image')\n",
    "    \n",
    "    # Build CRNN model\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "    labels = layers.Input(shape=[22], dtype='int64', name='label')\n",
    "    input_length = layers.Input(shape=[1], dtype='int64', name='input_length')\n",
    "    label_length = layers.Input(shape=[1], dtype='int64', name='label_length')\n",
    "    loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n",
    "        [labels, y_pred, label_length, input_length]\n",
    "    )\n",
    "    model_input = [image_input, labels, input_length, label_length]\n",
    "    model = Model(\n",
    "        inputs=model_input,\n",
    "        outputs=loss_out\n",
    "    )\n",
    "    y_func = tf.keras.backend.function(image_input, [y_pred])\n",
    "    return model, y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:27:53.248157Z",
     "start_time": "2020-11-30T08:27:53.238759Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_crnn_model(input_shape=(100,32,3), characters=TARGET_CHARACTERS):\n",
    "    num_chars = len(characters)+2\n",
    "    image_input = layers.Input(shape=input_shape, dtype='float32', name='input_image')\n",
    "\n",
    "    # Build CRNN model\n",
    "    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(image_input)\n",
    "    conv = layers.MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.MaxPooling2D(pool_size=(1, 2))(conv)\n",
    "    conv = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.BatchNormalization()(conv)\n",
    "    conv = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.MaxPooling2D(pool_size=(1, 2))(conv)     \n",
    "    feature = layers.Conv2D(512, (2, 2), activation='relu', kernel_initializer='he_normal')(conv)\n",
    "    sequnce = layers.Reshape(target_shape=(24, 512))(feature)\n",
    "    sequnce = layers.Dense(64, activation='relu')(sequnce)\n",
    "    sequnce = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(sequnce)\n",
    "    sequnce = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(sequnce)\n",
    "    y_pred = layers.Dense(num_chars, activation='softmax', name='output')(sequnce)\n",
    "\n",
    "    labels = layers.Input(shape=[22], dtype='int64', name='label')\n",
    "    input_length = layers.Input(shape=[1], dtype='int64', name='input_length')\n",
    "    label_length = layers.Input(shape=[1], dtype='int64', name='label_length')\n",
    "    loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n",
    "        [labels, y_pred, label_length, input_length]\n",
    "    )\n",
    "    model_input = [image_input, labels, input_length, label_length]\n",
    "    model = Model(\n",
    "        inputs=model_input,\n",
    "        outputs=loss_out\n",
    "    )\n",
    "    y_func = tf.keras.backend.function(image_input, [y_pred])\n",
    "    return model, y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:28:10.416676Z",
     "start_time": "2020-11-30T08:28:10.395502Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3d9e7b75bacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMJDatasetSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_CHARACTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMJDatasetSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALID_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_CHARACTERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHOME_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_checkpoint.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-fa7593b24bbb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, label_converter, batch_size, img_size, max_text_len, is_train, character)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_readers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadahead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeminit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num-samples'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "train_set = MJDatasetSequence(TRAIN_DATA_PATH, label_converter, batch_size=BATCH_SIZE, character=TARGET_CHARACTERS, is_train=True)\n",
    "val_set = MJDatasetSequence(VALID_DATA_PATH, label_converter, batch_size=BATCH_SIZE, character=TARGET_CHARACTERS)\n",
    "\n",
    "checkpoint_path = HOME_DIR + '/model_checkpoint.hdf5'\n",
    "\n",
    "model, y_func = build_crnn_model()\n",
    "sgd = tf.keras.optimizers.Adadelta(lr=0.1, clipnorm=5)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "ckp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_loss',\n",
    "    verbose=1, save_best_only=True, save_weights_only=True\n",
    ")\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'\n",
    ")\n",
    "model.fit(train_set,\n",
    "        steps_per_epoch=len(val_set),\n",
    "        epochs=100,\n",
    "        validation_data=val_set,\n",
    "        validation_steps=len(val_set),\n",
    "        callbacks=[ckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:27:58.596132Z",
     "start_time": "2020-11-30T08:27:54.738833Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8c37628f77a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_crnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_path' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "test_set = MJDatasetSequence(TEST_DATA_PATH, label_converter, batch_size=BATCH_SIZE, character=TARGET_CHARACTERS)\n",
    "\n",
    "model, y_func = build_crnn_model()\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "input_data = model.get_layer('input_image').output\n",
    "y_pred = model.get_layer('output').output\n",
    "model_pred = Model(inputs=input_data, outputs=y_pred)\n",
    "\n",
    "def decode_predict_ctc(out, chars = TARGET_CHARACTERS, top_paths = 1):\n",
    "    results = []\n",
    "    beam_width = 5\n",
    "    if beam_width < top_paths:\n",
    "        beam_width = top_paths\n",
    "    for i in range(top_paths):\n",
    "        indexes = K.get_value(\n",
    "            K.ctc_decode(\n",
    "                out, input_length = np.ones(out.shape[0]) * out.shape[1],\n",
    "                greedy =False , beam_width = beam_width, top_paths = top_paths\n",
    "            )[0][i]\n",
    "        )[0]\n",
    "        text = \"\"\n",
    "        for index in indexes:\n",
    "            text += chars[index]\n",
    "        results.append(text)\n",
    "    return results\n",
    "\n",
    "def check_inference(model, dataset, index = 5):\n",
    "    for i in range(index):\n",
    "        inputs, outputs = dataset[i]\n",
    "        img = dataset[i][0]['input_image'][0:1,:,:,:]\n",
    "        output = model_pred.predict(img)\n",
    "        result = decode_predict_ctc(output, chars=\"-\"+TARGET_CHARACTERS)[0].replace('-','')\n",
    "        print(\"Result: \\t\", result)\n",
    "        display(Image.fromarray(img[0].transpose(1,0,2).astype(np.uint8)))\n",
    "\n",
    "check_inference(model, test_set, index=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project : End-to-End OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text recognition을 위해 특화된 데이터셋 구성이 체계적으로 진행되었다.\n",
    "\n",
    "- 텍스트 이미지 리사이징, ctc loss 측정을 위한 라벨 인코딩, 배치처리 등이 적절히 수행되었다.\n",
    "2. CRNN 기반의 recognition 모델의 학습이 정상적으로 진행되었다.\n",
    "- 학습결과 loss가 안정적으로 감소하고 대부분의 문자인식 추론 결과가 정확하다.\n",
    "\n",
    "3. keras-ocr detector와 CRNN recognizer를 엮어 원본 이미지 입력으로부터 text가 출력되는 OCR이 End-to-End로 구성되었다.\n",
    "\n",
    "- 샘플 이미지를 원본으로 받아 OCR 수행 결과를 리턴하는 1개의 함수가 만들어졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:26:58.291657Z",
     "start_time": "2020-11-23T07:25:20.057076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement keras-ocr (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for keras-ocr\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.418727Z",
     "start_time": "2020-11-23T07:20:13.165268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-23 16:20:13--  https://aiffelstaticprd.blob.core.windows.net/media/original_images/sample.jpg\n",
      "Resolving aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)... 52.239.148.4\n",
      "Connecting to aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)|52.239.148.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 98665 (96K) [image/jpeg]\n",
      "Saving to: ‘/home/ubuntu/aiffel/ocr/sample.jpg’\n",
      "\n",
      "sample.jpg          100%[===================>]  96.35K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2020-11-23 16:20:13 (31.5 MB/s) - ‘/home/ubuntu/aiffel/ocr/sample.jpg’ saved [98665/98665]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ~/aiffel/ocr https://aiffelstaticprd.blob.core.windows.net/media/original_images/sample.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:26:58.320844Z",
     "start_time": "2020-11-23T07:26:58.301810Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-260bf1ce08cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSAMPLE_IMG_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sample.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_ocr'"
     ]
    }
   ],
   "source": [
    "from keras_ocr.detection import Detector\n",
    "SAMPLE_IMG_PATH = 'sample.jpg'\n",
    "detector = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.450216Z",
     "start_time": "2020-11-23T07:19:17.389Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_text(img_path):\n",
    "    # TODO\n",
    "\n",
    "        # 배치 크기를 위해서 dimension을 확장해주고 kera-ocr의 입력 차원에 맞게 H,W,C로 변경합니다.\n",
    "\n",
    "        # 배치의 첫 번째 결과만 가져옵니다.\n",
    "\n",
    "        # 시각화를 위해서 x와 y좌표를 변경해줍니다. (앞선 h dimension으로 인해 y,x로 표기됨)\n",
    "\n",
    "        cropped_imgs = []\n",
    "    for text_result in ocr_result:\n",
    "        img_draw.polygon(text_result, outline='red')\n",
    "        x_min = text_result[:,0].min() - 5\n",
    "        x_max = text_result[:,0].max() + 5\n",
    "        y_min = text_result[:,1].min() - 5\n",
    "        y_max = text_result[:,1].max() + 5\n",
    "        word_box = [x_min, y_min, x_max, y_max]\n",
    "        cropped_imgs.append(img_pil.crop(word_box))\n",
    "\n",
    "\n",
    "    return result_img, cropped_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.451679Z",
     "start_time": "2020-11-23T07:19:24.408Z"
    }
   },
   "outputs": [],
   "source": [
    "img_pil, cropped_img = detect_text(SAMPLE_IMG_PATH)\n",
    "display(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.453065Z",
     "start_time": "2020-11-23T07:19:38.572Z"
    }
   },
   "outputs": [],
   "source": [
    "def recognize_img(pil_img, input_img_size=(100,32)):\n",
    "    # TODO: 잘려진 단어 이미지를 인식하는 코드를 작성하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.454445Z",
     "start_time": "2020-11-23T07:19:41.832Z"
    }
   },
   "outputs": [],
   "source": [
    "for _img in cropped_img:\n",
    "    recognize_img(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
