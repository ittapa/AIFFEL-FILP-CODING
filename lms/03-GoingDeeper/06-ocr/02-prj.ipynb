{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  OCR\n",
    "\n",
    "- Overall sturcture of OCR\n",
    "- SynthText\n",
    "- Recognition model\n",
    "- End-to-End OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:10:59.294447Z",
     "start_time": "2020-11-23T07:10:59.288600Z"
    }
   },
   "source": [
    "# libarary install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:10:59.276946Z",
     "start_time": "2020-11-23T07:10:53.713564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Collecting lmdb\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/b6/18/48109367e0d1bc9f7eed0d387cd5b50dd0e19c299bbbfe8b21246455fa48/lmdb-1.0.0.tar.gz (876 kB)\n",
      "\u001b[K     |████████████████████████████████| 876 kB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lmdb\n",
      "  Building wheel for lmdb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lmdb: filename=lmdb-1.0.0-cp38-cp38-linux_x86_64.whl size=269146 sha256=de173b3cf588f2847cb5d60225f6536e1e074ac509f06cccf03e5fa0d43cf43f\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/68/4b/5c/4602efd08e13dbc70609a3e309cad8ea8b5383a08b1b84a5ed\n",
      "Successfully built lmdb\n",
      "Installing collected packages: lmdb\n",
      "Successfully installed lmdb-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:11:31.709679Z",
     "start_time": "2020-11-23T07:11:31.704632Z"
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "import six\n",
    "import math\n",
    "import lmdb\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data set \n",
    "\n",
    "- MJ Synth\n",
    "- SynthTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.path.join(os.getenv('HOME'),'aiffel/ocr')\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T06:21:14.371050Z",
     "start_time": "2020-11-23T06:21:14.253812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lsg/AIFFEL_LSG/lms/03-GoingDeeper/06-ocr\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition model\n",
    "\n",
    "- An End-to-End Trainable Neural Network for Image-based SequenceRecognition and Its Application to Scene Text Recognition\n",
    "\n",
    "- https://arxiv.org/pdf/1507.05717.pdf\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/e-23-2.crnn.png)\n",
    "\n",
    "\n",
    "- 구조\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/e-23-3.crnn_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:09:37.532303Z",
     "start_time": "2020-11-23T07:09:37.525710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of characters is 36\n"
     ]
    }
   ],
   "source": [
    "NUMBERS = \"0123456789\"\n",
    "ENG_CHAR_UPPER = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "TARGET_CHARACTERS = ENG_CHAR_UPPER + NUMBERS\n",
    "print(f\"The total number of characters is {len(TARGET_CHARACTERS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## path set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:11:48.910325Z",
     "start_time": "2020-11-23T07:11:48.905083Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "HOME_DIR = os.getenv('HOME')+'/AIFFEL_LSG/lms/03-GoingDeeper/06-ocr'\n",
    "\n",
    "TRAIN_DATA_PATH = HOME_DIR+'/MJ/MJ_train'\n",
    "VALID_DATA_PATH = HOME_DIR+'/MJ/MJ_valid'\n",
    "TEST_DATA_PATH = HOME_DIR+'/MJ/MJ_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:13:51.288591Z",
     "start_time": "2020-11-23T07:13:51.051367Z"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "/home/ubuntu/aiffel/ocr/MJ/MJ_train: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d75b6ad64faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_readers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadahead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeminit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: /home/ubuntu/aiffel/ocr/MJ/MJ_train: No such file or directory"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "env = lmdb.open(TRAIN_DATA_PATH, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "with env.begin(write=False) as txn:\n",
    "    for index in range(1, 5):\n",
    "        label_key = 'label-%09d'.encode() % index\n",
    "        label = txn.get(label_key).decode('utf-8')\n",
    "        img_key = 'image-%09d'.encode() % index\n",
    "        imgbuf = txn.get(img_key)\n",
    "        buf = six.BytesIO()\n",
    "        buf.write(imgbuf)\n",
    "        buf.seek(0)\n",
    "        try:\n",
    "            img = Image.open(buf).convert('RGB')\n",
    "\n",
    "        except IOError:\n",
    "            img = Image.new('RGB', (100, 32))\n",
    "            label = '-'\n",
    "        width, height = img.size\n",
    "        print('original image width:{}, height:{}'.format(width, height))\n",
    "        \n",
    "        target_width = min(int(width*32/height), 100)\n",
    "        target_img_size = (target_width,32 )\n",
    "        \n",
    "        print('target_img_size:{}'.format(target_img_size))\n",
    "        \n",
    "        img = np.array(img.resize(target_img_size)).transpose(1,0,2)\n",
    "       \n",
    "        print('display img shape:{}'.format(img.shape))\n",
    "        print('label:{}'.format(label))\n",
    "        display(Image.fromarray(img.transpose(1,0,2).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:15:55.225988Z",
     "start_time": "2020-11-23T07:15:55.212307Z"
    }
   },
   "outputs": [],
   "source": [
    "class MJDatasetSequence(Sequence):\n",
    "    def __init__(self, \n",
    "                      dataset_path,\n",
    "                      label_converter,\n",
    "                      batch_size=1,\n",
    "                      img_size=(100,32),\n",
    "                      max_text_len=22,\n",
    "                      is_train=False,\n",
    "                      character=''\n",
    "                ):\n",
    "        \n",
    "        self.label_converter = label_converter\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.character = character\n",
    "        self.is_train = is_train\n",
    "        self.divide_length = 100\n",
    "\n",
    "        self.env = lmdb.open(dataset_path, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            num_samples = int(txn.get('num-samples'.encode()))\n",
    "            self.num_samples = int(num_samples)\n",
    "            self.index_list = [index + 1 for index in range(self.num_samples)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return math.ceil(self.num_samples/self.batch_size/self.divide_length)\n",
    "        return math.ceil(self.num_samples/self.batch_size/self.divide_length)\n",
    "    \n",
    "    def _get_img_label(self, index):\n",
    "        # Return image array and label in string\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            label_key = 'label-%09d'.encode() % index\n",
    "            label = txn.get(label_key).decode('utf-8')\n",
    "            img_key = 'image-%09d'.encode() % index\n",
    "            imgbuf = txn.get(img_key)\n",
    "\n",
    "            buf = six.BytesIO()\n",
    "            buf.write(imgbuf)\n",
    "            buf.seek(0)\n",
    "            try:\n",
    "                img = Image.open(buf).convert('RGB')\n",
    "\n",
    "            except IOError:\n",
    "                img = Image.new('RGB', self.img_size)\n",
    "                label = '-'\n",
    "            width, height = img.size\n",
    "            \n",
    "            target_width = min(int(width*self.img_size[1]/height), self.img_size[0])\n",
    "            target_img_size = (target_width,self.img_size[1] )\n",
    "            img = np.array(img.resize(target_img_size)).transpose(1,0,2)\n",
    "            label = label.upper()[:self.max_text_len]\n",
    "            out_of_char = f'[^{self.character}]'\n",
    "            label = re.sub(out_of_char, '', label)\n",
    "\n",
    "        return (img, label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indicies = self.index_list[\n",
    "            idx*self.batch_size:\n",
    "            (idx+1)*self.batch_size\n",
    "        ]\n",
    "        input_images = np.zeros([self.batch_size, *self.img_size, 3])\n",
    "        labels = np.zeros([self.batch_size, self.max_text_len], dtype='int64')\n",
    "\n",
    "        input_length = np.ones([self.batch_size], dtype='int64')*self.max_text_len\n",
    "        label_length = np.ones([self.batch_size], dtype='int64')\n",
    "\n",
    "        for i, index in enumerate(batch_indicies):\n",
    "            img, label = self._get_img_label(index)\n",
    "            encoded_label = self.label_converter.encode(label)\n",
    "            width = img.shape[0]\n",
    "            input_images[i,:width,:,:] = img\n",
    "            if len(encoded_label) > self.max_text_len:\n",
    "                continue\n",
    "            labels[i,0:len(encoded_label)] = encoded_label\n",
    "            label_length[i] = len(encoded_label)\n",
    "\n",
    "        inputs = {\n",
    "            'input_image': input_images,\n",
    "            'label': labels,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "        }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size, 1])}\n",
    "        return inputs, outputs\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.index_list =  [index + 1 for index in range(self.num_samples)]\n",
    "        if self.is_train :\n",
    "            np.random.shuffle(self.index_list)\n",
    "            return self.index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:15:58.099005Z",
     "start_time": "2020-11-23T07:15:58.094620Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabelConverter(object):\n",
    "     \"\"\" Convert between text-label and text-index \"\"\"\n",
    "\n",
    "     def __init__(self, character):\n",
    "         self.character = \"-\" + character\n",
    "         self.label_map = dict()\n",
    "         for i, char in enumerate(self.character):\n",
    "             self.label_map[char] = i\n",
    "\n",
    "     def encode(self, text):\n",
    "         encoded_label = []\n",
    "         # [[YOUR CODE]]\n",
    "\n",
    "         return np.array(encoded_label)\n",
    "\n",
    "     def decode(self, encoded_label):\n",
    "         target_characters = list(self.character)\n",
    "         decoded_label = \"\"\n",
    "         for encode in encoded_label:\n",
    "             decoded_label += self.character[encode]\n",
    "         return decoded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:16:03.453117Z",
     "start_time": "2020-11-23T07:16:03.449440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encdoded_text:  []\n",
      "Decoded_text:  \n"
     ]
    }
   ],
   "source": [
    "label_converter = LabelConverter(TARGET_CHARACTERS)\n",
    "\n",
    "encdoded_text = label_converter.encode('HELLO')\n",
    "print(\"Encdoded_text: \", encdoded_text)\n",
    "decoded_text = label_converter.decode(encdoded_text)\n",
    "print(\"Decoded_text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:16:22.178774Z",
     "start_time": "2020-11-23T07:16:22.175535Z"
    }
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args): # CTC loss를 계산하기 위한 Lambda 함수\n",
    "    labels, y_pred, label_length, input_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:16:27.706869Z",
     "start_time": "2020-11-23T07:16:27.700156Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_crnn_model(input_shape=(100,32,3), characters=TARGET_CHARACTERS):\n",
    "    num_chars = len(characters)+2\n",
    "    image_input = layers.Input(shape=input_shape, dtype='float32', name='input_image')\n",
    "    \n",
    "    # Build CRNN model\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "    labels = layers.Input(shape=[22], dtype='int64', name='label')\n",
    "    input_length = layers.Input(shape=[1], dtype='int64', name='input_length')\n",
    "    label_length = layers.Input(shape=[1], dtype='int64', name='label_length')\n",
    "    loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n",
    "        [labels, y_pred, label_length, input_length]\n",
    "    )\n",
    "    model_input = [image_input, labels, input_length, label_length]\n",
    "    model = Model(\n",
    "        inputs=model_input,\n",
    "        outputs=loss_out\n",
    "    )\n",
    "    y_func = tf.keras.backend.function(image_input, [y_pred])\n",
    "    return model, y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:16:43.032073Z",
     "start_time": "2020-11-23T07:16:43.022001Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_crnn_model(input_shape=(100,32,3), characters=TARGET_CHARACTERS):\n",
    "    num_chars = len(characters)+2\n",
    "    image_input = layers.Input(shape=input_shape, dtype='float32', name='input_image')\n",
    "\n",
    "    # Build CRNN model\n",
    "    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(image_input)\n",
    "    conv = layers.MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.MaxPooling2D(pool_size=(1, 2))(conv)\n",
    "    conv = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.BatchNormalization()(conv)\n",
    "    conv = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = layers.MaxPooling2D(pool_size=(1, 2))(conv)     \n",
    "    feature = layers.Conv2D(512, (2, 2), activation='relu', kernel_initializer='he_normal')(conv)\n",
    "    sequnce = layers.Reshape(target_shape=(24, 512))(feature)\n",
    "    sequnce = layers.Dense(64, activation='relu')(sequnce)\n",
    "    sequnce = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(sequnce)\n",
    "    sequnce = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(sequnce)\n",
    "    y_pred = layers.Dense(num_chars, activation='softmax', name='output')(sequnce)\n",
    "\n",
    "    labels = layers.Input(shape=[22], dtype='int64', name='label')\n",
    "    input_length = layers.Input(shape=[1], dtype='int64', name='input_length')\n",
    "    label_length = layers.Input(shape=[1], dtype='int64', name='label_length')\n",
    "    loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n",
    "        [labels, y_pred, label_length, input_length]\n",
    "    )\n",
    "    model_input = [image_input, labels, input_length, label_length]\n",
    "    model = Model(\n",
    "        inputs=model_input,\n",
    "        outputs=loss_out\n",
    "    )\n",
    "    y_func = tf.keras.backend.function(image_input, [y_pred])\n",
    "    return model, y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:17:06.570088Z",
     "start_time": "2020-11-23T07:17:06.540059Z"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "/home/ubuntu/aiffel/ocr/MJ/MJ_train: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3d9e7b75bacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMJDatasetSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_CHARACTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMJDatasetSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALID_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_CHARACTERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHOME_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_checkpoint.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-fa7593b24bbb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, label_converter, batch_size, img_size, max_text_len, is_train, character)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_readers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadahead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeminit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num-samples'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: /home/ubuntu/aiffel/ocr/MJ/MJ_train: No such file or directory"
     ]
    }
   ],
   "source": [
    "train_set = MJDatasetSequence(TRAIN_DATA_PATH, label_converter, batch_size=BATCH_SIZE, character=TARGET_CHARACTERS, is_train=True)\n",
    "val_set = MJDatasetSequence(VALID_DATA_PATH, label_converter, batch_size=BATCH_SIZE, character=TARGET_CHARACTERS)\n",
    "\n",
    "checkpoint_path = HOME_DIR + '/model_checkpoint.hdf5'\n",
    "\n",
    "model, y_func = build_crnn_model()\n",
    "sgd = tf.keras.optimizers.Adadelta(lr=0.1, clipnorm=5)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "ckp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_loss',\n",
    "    verbose=1, save_best_only=True, save_weights_only=True\n",
    ")\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'\n",
    ")\n",
    "model.fit(train_set,\n",
    "        steps_per_epoch=len(val_set),\n",
    "        epochs=100,\n",
    "        validation_data=val_set,\n",
    "        validation_steps=len(val_set),\n",
    "        callbacks=[ckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:17:28.233483Z",
     "start_time": "2020-11-23T07:17:28.211875Z"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "/home/ubuntu/aiffel/ocr/MJ/MJ_test: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8c37628f77a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMJDatasetSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_CHARACTERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_crnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-fa7593b24bbb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, label_converter, batch_size, img_size, max_text_len, is_train, character)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_readers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadahead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeminit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num-samples'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: /home/ubuntu/aiffel/ocr/MJ/MJ_test: No such file or directory"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "test_set = MJDatasetSequence(TEST_DATA_PATH, label_converter, batch_size=BATCH_SIZE, character=TARGET_CHARACTERS)\n",
    "\n",
    "model, y_func = build_crnn_model()\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "input_data = model.get_layer('input_image').output\n",
    "y_pred = model.get_layer('output').output\n",
    "model_pred = Model(inputs=input_data, outputs=y_pred)\n",
    "\n",
    "def decode_predict_ctc(out, chars = TARGET_CHARACTERS, top_paths = 1):\n",
    "    results = []\n",
    "    beam_width = 5\n",
    "    if beam_width < top_paths:\n",
    "        beam_width = top_paths\n",
    "    for i in range(top_paths):\n",
    "        indexes = K.get_value(\n",
    "            K.ctc_decode(\n",
    "                out, input_length = np.ones(out.shape[0]) * out.shape[1],\n",
    "                greedy =False , beam_width = beam_width, top_paths = top_paths\n",
    "            )[0][i]\n",
    "        )[0]\n",
    "        text = \"\"\n",
    "        for index in indexes:\n",
    "            text += chars[index]\n",
    "        results.append(text)\n",
    "    return results\n",
    "\n",
    "def check_inference(model, dataset, index = 5):\n",
    "    for i in range(index):\n",
    "        inputs, outputs = dataset[i]\n",
    "        img = dataset[i][0]['input_image'][0:1,:,:,:]\n",
    "        output = model_pred.predict(img)\n",
    "        result = decode_predict_ctc(output, chars=\"-\"+TARGET_CHARACTERS)[0].replace('-','')\n",
    "        print(\"Result: \\t\", result)\n",
    "        display(Image.fromarray(img[0].transpose(1,0,2).astype(np.uint8)))\n",
    "\n",
    "check_inference(model, test_set, index=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project : End-to-End OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text recognition을 위해 특화된 데이터셋 구성이 체계적으로 진행되었다.\n",
    "\n",
    "- 텍스트 이미지 리사이징, ctc loss 측정을 위한 라벨 인코딩, 배치처리 등이 적절히 수행되었다.\n",
    "2. CRNN 기반의 recognition 모델의 학습이 정상적으로 진행되었다.\n",
    "- 학습결과 loss가 안정적으로 감소하고 대부분의 문자인식 추론 결과가 정확하다.\n",
    "\n",
    "3. keras-ocr detector와 CRNN recognizer를 엮어 원본 이미지 입력으로부터 text가 출력되는 OCR이 End-to-End로 구성되었다.\n",
    "\n",
    "- 샘플 이미지를 원본으로 받아 OCR 수행 결과를 리턴하는 1개의 함수가 만들어졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.152710Z",
     "start_time": "2020-11-23T07:18:34.907954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPConnectionPool(host='mirror.kakao.com', port=80): Read timed out. (read timeout=15)\")': /pypi/simple/keras-ocr/\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement keras-ocr (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for keras-ocr\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.418727Z",
     "start_time": "2020-11-23T07:20:13.165268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-23 16:20:13--  https://aiffelstaticprd.blob.core.windows.net/media/original_images/sample.jpg\n",
      "Resolving aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)... 52.239.148.4\n",
      "Connecting to aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)|52.239.148.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 98665 (96K) [image/jpeg]\n",
      "Saving to: ‘/home/ubuntu/aiffel/ocr/sample.jpg’\n",
      "\n",
      "sample.jpg          100%[===================>]  96.35K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2020-11-23 16:20:13 (31.5 MB/s) - ‘/home/ubuntu/aiffel/ocr/sample.jpg’ saved [98665/98665]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ~/aiffel/ocr https://aiffelstaticprd.blob.core.windows.net/media/original_images/sample.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.447125Z",
     "start_time": "2020-11-23T07:20:13.425401Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-260bf1ce08cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSAMPLE_IMG_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sample.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_ocr'"
     ]
    }
   ],
   "source": [
    "from keras_ocr.detection import Detector\n",
    "SAMPLE_IMG_PATH = 'sample.jpg'\n",
    "detector = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.450216Z",
     "start_time": "2020-11-23T07:19:17.389Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_text(img_path):\n",
    "    # TODO\n",
    "\n",
    "        # 배치 크기를 위해서 dimension을 확장해주고 kera-ocr의 입력 차원에 맞게 H,W,C로 변경합니다.\n",
    "\n",
    "        # 배치의 첫 번째 결과만 가져옵니다.\n",
    "\n",
    "        # 시각화를 위해서 x와 y좌표를 변경해줍니다. (앞선 h dimension으로 인해 y,x로 표기됨)\n",
    "\n",
    "        cropped_imgs = []\n",
    "    for text_result in ocr_result:\n",
    "        img_draw.polygon(text_result, outline='red')\n",
    "        x_min = text_result[:,0].min() - 5\n",
    "        x_max = text_result[:,0].max() + 5\n",
    "        y_min = text_result[:,1].min() - 5\n",
    "        y_max = text_result[:,1].max() + 5\n",
    "        word_box = [x_min, y_min, x_max, y_max]\n",
    "        cropped_imgs.append(img_pil.crop(word_box))\n",
    "\n",
    "\n",
    "    return result_img, cropped_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.451679Z",
     "start_time": "2020-11-23T07:19:24.408Z"
    }
   },
   "outputs": [],
   "source": [
    "img_pil, cropped_img = detect_text(SAMPLE_IMG_PATH)\n",
    "display(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.453065Z",
     "start_time": "2020-11-23T07:19:38.572Z"
    }
   },
   "outputs": [],
   "source": [
    "def recognize_img(pil_img, input_img_size=(100,32)):\n",
    "    # TODO: 잘려진 단어 이미지를 인식하는 코드를 작성하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T07:20:13.454445Z",
     "start_time": "2020-11-23T07:19:41.832Z"
    }
   },
   "outputs": [],
   "source": [
    "for _img in cropped_img:\n",
    "    recognize_img(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
